# Multilingual NMT Edge Training Pipeline

A modular and production-ready pipeline for training, analyzing, quantizing, and packaging multilingual NMT (Neural Machine Translation) models for edge-friendly deployment.  
The project provides tools for model inspection, layer-wise size estimation, quantization planning, dataset handling, workspace packaging, and reproducible evaluation.

---

## üöÄ Key Features

### üîπ **1. Modular Architecture**
A clean, maintainable Python codebase organized into:
- **Model utilities** (loading, tokenizer checks, layer summaries)
- **Dataset and manifest tools** (JSONL creation, manifest generation)
- **Quantization planning** (layer size estimates, quantizable layers list)
- **Workspace packaging** for deployment
- **Training orchestration** with CLI support

### üîπ **2. Rich Metadata & Analysis Tools**
The project generates a variety of useful analysis files:
- `layer_sizes_summary.csv` ‚Äì per-layer FP16 & int4 estimated sizes  
- `size_estimates.json/csv` ‚Äì global memory footprint estimates  
- `quantizable_layers_list.csv` ‚Äì layers compatible with quantization  
- `model_metadata.json` ‚Äì model configuration summary  
- `tokenizer_sanity.json` ‚Äì tokenizer validation  
- `quant_test_report.json` ‚Äì quantization verification  
- `sample_layers.json` ‚Äì sampled layer statistics  

These metadata files are small, version-controlled, and crucial for reproducibility.

### üîπ **3. Dataset Support**
Includes utilities for:
- JSONL dataset creation  
- Manifest building  
- Language list management  
- Support for multilingual evaluation sets such as FLORES-200

*(Large datasets are not stored in the repository; only metadata such as `dataset_overview.json` is included.)*

### üîπ **4. Edge-Friendly Workflow**
Built to support:
- Low-precision weight formats (e.g., int4)  
- Adapter loading and packaging  
- Exporting and preparing workspaces for FPGA or low-resource deployment  
- Weight/embedding manifests and inspection tools  

---

## üìÅ Directory Structure

my_project/
‚îú‚îÄ README.md
‚îú‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ notebooks/
‚îÇ  ‚îî‚îÄ training_script.ipynb
‚îÇ
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ __main__.py
‚îÇ  ‚îú‚îÄ config.py
‚îÇ  ‚îú‚îÄ utils.py
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ data/
‚îÇ  ‚îÇ  ‚îî‚îÄ manifest_and_io.py
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ model/
‚îÇ  ‚îÇ  ‚îú‚îÄ loader.py
‚îÇ  ‚îÇ  ‚îî‚îÄ layers_summary.py
‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ train.py
‚îÇ
‚îú‚îÄ scripts/
‚îÇ  ‚îú‚îÄ package_workspace.py
‚îÇ  ‚îî‚îÄ run_train.sh
‚îÇ
‚îú‚îÄ metadata/
‚îÇ  ‚îú‚îÄ layer_sizes_summary.csv
‚îÇ  ‚îú‚îÄ size_estimates.csv
‚îÇ  ‚îú‚îÄ size_estimates.json
‚îÇ  ‚îú‚îÄ quantizable_layers_list.csv
‚îÇ  ‚îú‚îÄ model_metadata.json
‚îÇ  ‚îú‚îÄ tokenizer_sanity.json
‚îÇ  ‚îú‚îÄ quant_test_report.json
‚îÇ  ‚îú‚îÄ sample_layers.json
‚îÇ  ‚îî‚îÄ dataset_overview.json
‚îÇ
‚îî‚îÄ artifacts/
   ‚îú‚îÄ workspace_package.zip
   ‚îú‚îÄ logs/
   ‚îî‚îÄ datasets/


yaml
Copy code

> **Note**  
> Large artifacts such as model weights (`*.wbin`), embeddings, adapters, or large datasets are **not versioned** and belong in the `artifacts/` directory or external storage.

---

## üîß Installation

### **1. Create a virtual environment**
```bash
python -m venv venv
source venv/bin/activate   # macOS / Linux
venv\Scripts\activate      # Windows
2. Install dependencies
bash
Copy code
pip install -r requirements.txt
‚ñ∂ Usage
Run the demo training pipeline
bash
Copy code
python -m src --demo
This executes:

Model + tokenizer loading

Layer size summary generation

Creation of sample JSONL dataset

Manifest generation

Storage of metadata in /metadata and /artifacts

Package the entire workspace
bash
Copy code
python scripts/package_workspace.py
Outputs:

bash
Copy code
artifacts/workspace_package.zip
Run from the shell script
bash
Copy code
bash scripts/run_train.sh
üì¶ Metadata Files Explained
File	Description
layer_sizes_summary.csv	Per-layer FP16 & estimated INT4 sizes
size_estimates.json / csv	Total model memory estimates
quantizable_layers_list.csv	Identified layers safe for quantization
model_metadata.json	General model configuration metadata
tokenizer_sanity.json	Tokenizer validation (vocab size, test samples)
quant_test_report.json	Quantization verification summary
dataset_overview.json	Summary of dataset structure (e.g., FLORES-200)
sample_layers.json	Example of random layer structure stats

These files are intentionally small and version-controlled.

üìö Dataset Usage
The project supports multilingual datasets such as:

FLORES-200

Custom parallel corpora in JSONL format

Place any large dataset in:

bash
Copy code
artifacts/datasets/
Only include small metadata files (e.g., dataset_overview.json) in the repository.

üß© Extending the Project
You can easily add:

Adapter-based fine-tuning (LoRA, IA3, etc.)

Quantization-aware training

Export to ONNX, TensorRT, or FPGA

Evaluation scripts

Model compression workflows

The modular structure makes this straightforward.

üìÑ License
MIT License. You are free to use, modify, and distribute this project.

ü§ù Contributing
Contributions are welcome!
Feel free to open:

Issues

Pull requests

Feature requests











